import os
import logging
from flask import Flask, request, render_template, jsonify
from PIL import Image
import torch
from transformers import ViTForImageClassification, ViTImageProcessor
from torchvision.transforms import Compose, Normalize, ToTensor
import time

# Configure logging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

app = Flask(__name__, static_folder='static')

# Paths
MODEL_PATH = './Notebook/model/deepfake_vs_real_image_detection'  # Corrected path
UPLOAD_FOLDER = './uploads'
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['MAX_CONTENT_LENGTH'] = 50 * 1024 * 1024  # 50MB limit

# Ensure upload folder exists
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

# Load model and processor
device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")  # Use conditional device
logger.debug(f"Using device: {device}")

try:
    model = ViTForImageClassification.from_pretrained(MODEL_PATH).to(device)
    processor = ViTImageProcessor.from_pretrained(MODEL_PATH)
    model.eval()
    logger.debug("Model and processor loaded successfully")
except Exception as e:
    logger.error(f"Failed to load model or processor: {str(e)}")
    raise

# Image transformation
normalize = Normalize(mean=processor.image_mean, std=processor.image_std)
transform = Compose([ToTensor(), normalize])

@app.route('/')
def index():
    return render_template('index.html')  # Changed to index.html

@app.route('/predict', methods=['POST'])
def predict():
    start_time = time.time()
    logger.debug("Received predict request")

    if 'file' not in request.files:
        logger.warning("No file part in request")
        return jsonify({'error': 'No file uploaded'}), 400

    file = request.files['file']
    if file.filename == '' or not file.filename.lower().endswith(('.jpg', '.jpeg')):
        logger.warning("Invalid file format or no file selected")
        return jsonify({'error': 'Please upload a JPG image'}), 400

    file_path = os.path.join(app.config['UPLOAD_FOLDER'], file.filename)
    try:
        file.save(file_path)
        logger.debug(f"Saved JPG file to {file_path}")
    except Exception as e:
        logger.error(f"Failed to save file: {str(e)}")
        return jsonify({'error': 'Failed to save uploaded file'}), 500

    try:
        image = Image.open(file_path)
        if image.format not in ['JPEG', 'JPG']:
            raise ValueError("Image format is not JPG/JPEG")
        image = image.convert('RGB').resize((128, 128), Image.Resampling.LANCZOS)
        pixel_values = transform(image).unsqueeze(0).to(device)

        with torch.no_grad():
            start_inference = time.time()
            outputs = model(pixel_values)
            logger.debug(f"Inference time: {time.time() - start_inference:.2f}s")
            logits = outputs.logits
            probabilities = torch.softmax(logits, dim=-1)
            predicted_class_idx = logits.argmax(-1).item()
            confidence = probabilities[0][predicted_class_idx].item() * 100
            prediction = model.config.id2label[predicted_class_idx]

        logger.debug(f"Prediction: {prediction}, Confidence: {confidence}%")
        os.remove(file_path)
        logger.debug(f"Removed file {file_path}")

        total_time = time.time() - start_time
        logger.debug(f"Total processing time: {total_time:.2f}s")
        return jsonify({'prediction': prediction, 'confidence': f'{confidence:.2f}%'})

    except Exception as e:
        logger.error(f"Error during prediction: {str(e)}")
        if os.path.exists(file_path):
            os.remove(file_path)
            logger.debug(f"Cleaned up file {file_path}")
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5001)  # Use port 5001